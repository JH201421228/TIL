# 로지스틱 회귀(Logistic regression)  
**정의**: 로지스틱 회귀는 **로짓(logit)**—확률의 로그-오즈(log-odds)—를 **입력의 선형결합**으로 모델링하고, **시그모이드(sigmoid)**로 확률을 출력하는 **이진 분류(binary classification)** 모델.

**핵심 아이디어**: **베르누이(Bernoulli) 우도 최대화(MLE)** → **음의 로그우도** = **이진 크로스엔트로피(BCE)** 최소화. 그라디언트는 “예측 − 정답”의 형태로 단순하다. 

**언제 쓰나**: 스팸/햄, 정상/이상, 클릭/미클릭처럼 **두 클래스** 확률을 직접 예측하고 **해석성(odds, OR)** 이 필요한 상황. 

---

## A. 용어사전(Glossary)

- **시그모이드(sigmoid)**: 실수 z를 (0,1)로 매핑: $\sigma(z)=1/(1+e^{-z})$. 확률로 해석하기 좋아서 로지스틱 회귀에 사용.
- **로짓(logit)**: $\mathrm{logit}(p)=\log\frac{p}{1-p}$. 확률 pp의 로그-오즈. 선형결합과 자연스럽게 연결된다.
- **오즈(odds)**: 사건이 일어날 확률 대비 일어나지 않을 확률 비 $\frac{p}{1-p}.$ 계수의 지수 $e^{\beta}$는 **오즈비(OR)**.
- **이진 크로스엔트로피(BCE)**: $L=-[y\log \hat p + (1-y)\log(1-\hat p)]$. 베르누이 음의 로그우도.
- **BCEWithLogits**: “시그모이드+BCE”를 **수치안정성** 좋게 합친 구현(로그-합-지수, log-sum-exp 사용).

---

## B. 큰 그림(What / Why / How)

### What: 개념/모델

- **모델식**: $\hat p(x)=\sigma(w^\top x + b), \sigma(z)=1/(1+e^{-z})$.
- **해석**: $\log\frac{\hat p}{1-\hat p} = w^\top x + b$ — **로짓이 선형**이므로 계수 해석(OR)이 쉽다.

### Why: 한계/문제

- **왜 시그모이드인가?**
    
    (i) (0,1) 범위로 확률 해석 용이, (ii) **로짓-선형**이 베르누이 GLM의 **정준 링크**여서 MLE가 깔끔, (iii) 다클래스 확장은 softmax로 일반화.
    
- **주의**: 큰 |z|에서 기울기 $\sigma(z)(1-\sigma(z))$가 작아 **포화(saturation)** → 학습 느려짐.

### How: 3–5 단계 메커니즘

1. 입력 전처리(스케일링/표준화)
2. 선형결합 $z=w^\top x + b$
3. 확률화 $\hat p=\sigma(z)$
4. BCE 손실 계산
5. ∇로 w,b 업데이트(미니배치, Adam 등)