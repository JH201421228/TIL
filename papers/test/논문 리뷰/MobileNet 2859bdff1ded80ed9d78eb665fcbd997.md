# MobileNet

소유자: 주헌 박

- 핵심 아이디어
    - 표준 합성곱을 “채널별 필터링(Depthwise)”과 “채널 결합(1×1 Pointwise)” 두 단계로 나눠 연산과 파라미터를 급감시킵니다. 결과적으로 모델 크기와 계산량이 크게 줄어듭니다.
    - 구현 관점에서도 연산의 95%를 1×1 합성곱에 몰아넣어 고도로 최적화된 GEMM으로 빠르게 처리하게 설계했습니다(파라미터의 약 75%도 1×1에 존재).
- 두 개의 전역 하이퍼파라미터로 손쉬운 크기–정확도 트레이드오프
    - 폭 배수(α, width multiplier): 모든 채널 수를 α배로 줄여 모델을 “옆으로 얇게” 만듭니다. 계산량과 파라미터가 대략 α²에 비례해 줄어듭니다(α∈{1, 0.75, 0.5, 0.25} 등).
    - 해상도 배수(ρ, resolution multiplier): 입력/내부 특성맵 해상도를 ρ배로 낮춰 계산량을 ρ²만큼 줄입니다(일반적으로 224/192/160/128 입력).
    - 이 두 축을 조합하면 정확도는 “완만하게” 감소하며, 매우 작은 영역(예: α=0.25)에서만 급락이 나타납니다.
- 학습 세팅의 포인트
    - TensorFlow에서 RMSprop, 비동기 경사하강을 사용했고, 작은 모델 특성상 규제를 약하게(특히 depthwise 필터에는 weight decay 거의 없음), 강한 왜곡 증강을 줄였습니다.
- 대표 성능(이미지넷 분류, 비교 포함)
    - 기본 MobileNet(224 입력)은 Top-1 70.6%, 약 5.69×10^8 Mult-Adds, 4.2M 파라미터.
    - VGG16(71.5%)과 정확도는 비슷하지만, 연산은 약 27배, 파라미터는 32배 이상 작습니다. GoogLeNet(69.8%)보다도 더 정확하면서 더 작고 가볍습니다.
- 다른 과제에도 광범위하게 적용
    - 세부 종류 인식(Stanford Dogs): 적은 연산/모델 크기로 거의 최상위 성능에 근접.
    - 대규모 지오로컬라이제이션(PlaNet): 훨씬 작은 MobileNet 백본으로도 강력한 성능 유지.
    - 얼굴 속성 분류: 지식 증류와 결합해 연산량 1% 수준까지 줄여도 유사한 mAP 달성.
    - 객체 탐지(COCO, SSD/Faster-RCNN): VGG/Inception 대비 연산·모델 크기를 크게 줄이면서 경쟁력 있는 mAP 확보.
    - FaceNet 임베딩 증류: 매우 작은 모델로도 준수한 정확도 유지.
- 요약 한 줄 평
    - MobileNet은 “깊이별+포인트와이즈 분해”라는 한 수로, 휴대·엣지 환경에서 쓰기 좋은 속도·크기·정확도 균형점을 체계적으로 제공하는 설계 철학과 툴킷(α, ρ)을 제시합니다. 이미지넷부터 탐지, 지오로컬라이제이션, 얼굴 속성·임베딩까지 일관되게 통하는 범용 ‘경량 표준안’을 사실상 열어젖혔다고 볼 수 있어요.