# CLIP

소유자: 주헌 박

- **문제의식과 아이디어**: 기존 비전 모델은 고정된 라벨 집합에만 맞춰 학습되어 유연하지 않습니다. 이미지와 함께 붙어 있는 **자연어 텍스트**를 감독 신호로 삼아, “어떤 캡션이 어떤 이미지와 짝인지 맞추는” 간단한 사전학습 과제를 통해 범용 시각 표현을 효율적으로 학습하자—가 CLIP의 출발점입니다. 이렇게 학습하면 모델이 배운 개념을 **자연어 프롬프트**로 참조할 수 있어 **제로샷(Zero-shot) 전이**가 가능해집니다.
- **데이터셋(WIT)**: 저자들은 공개 웹에서 **4억 쌍의 (이미지, 텍스트)**를 수집해 대규모 학습을 수행했습니다. 텍스트 쿼리 50만 개를 기준으로 폭넓은 개념을 커버하려고 했고, 쿼리마다 최대 2만 쌍을 포함하도록 균형을 맞췄습니다. 이 데이터셋을 **WIT(WebImageText)**라고 부릅니다.
- **학습 방식(대조학습, Contrastive)**: 한 배치에 N개의 (이미지, 텍스트) 쌍이 있을 때, 실제로 짝지어진 N개는 **코사인 유사도**를 크게, 나머지 (N^2-N)개의 잘못된 조합은 작게 만들도록 **쌍방향 Cross-Entropy** 대조손실을 최적화합니다. 이미지 인코더와 텍스트 인코더를 **공동으로 학습**해 하나의 다중모달 임베딩 공간을 형성합니다. 이 접근은 캡션의 **정확한 단어 예측**보다 효율적이며, 제로샷 전이 속도에서 큰 이득을 보였습니다.
- **모델 구성과 학습 세부**: 이미지 측은 ResNet 계열과 Vision Transformer(ViT)를, 텍스트 측은 BPE 사전을 쓰는 Transformer 인코더를 사용했습니다. **32 epoch**, **미니배치 32,768**, **Adam + decoupled weight decay**, **코사인 러닝레이트 스케줄**로 학습했습니다. 텍스트는 최대 길이 76 토큰, [EOS] 위치의 은닉을 텍스트 표현으로 사용합니다.
- **제로샷 분류 성능**: 별도 라벨로 미세조정 없이 **ImageNet Top-1 76.2%**를 달성하여, 원조 ResNet-50의 정확도를 **제로샷으로** 맞췄습니다. Top-5는 95%로 Inception-V4 수준이며, 이는 자연어 프롬프트만으로도 강력한 분류기가 생성됨을 시사합니다.
- **분포 이동에 대한 강건성**: 표준 ImageNet 학습 모델 대비, CLIP의 **제로샷 분류기**는 ImageNet-V2, ImageNet-A/R, ObjectNet, Sketch 등 **자연 분포 이동** 데이터셋에서 **일관되게 더 강건**했습니다. 평균적으로 **“로버스트니스 갭”을 최대 75% 축소**합니다. 다만 ImageNet에 맞춘 적응(선형 분류기 학습)은 ImageNet 정확도를 **+9.2%p(→85.4%)** 올리는 대신 분포 이동 성능은 소폭 하락하였습니다.
- **범용 전이와 잠재 능력**: 제로샷으로 **30개+ 벤치마크**(OCR, 액션 인식, 지오로컬라이제이션, 세밀 분류 등)에 비미세조정 상태로도 경쟁력 있는 전이를 보여줍니다. 학습 중 **원시 OCR 능력**이 자연스럽게 생겨나는 등, 다양한 태스크에 걸친 **과제 학습(task learning)**이 관찰됩니다.
- **프롬프트 설계 효과**: 제로샷 평가에서 클래스 설명 앞에 **“a photo of”** 같은 문구를 덧붙이는 간단한 프롬프트 엔지니어링만으로도 R@1이 1–2포인트 향상됩니다(이미지-텍스트 검색).
- **한계와 사회적 고려**: CLIP은 **데이터 효율성** 문제가 남아 있고(거대한 데이터로 상쇄), 평가 셋 선택과 검증 셋 반복 확인 등 **평가 편향** 소지가 언급됩니다. 또한 **웹 텍스트·이미지의 편향**을 그대로 학습하여 **사회적 편향**이 드러나며, “클래스 설계(class design)”나 라벨 임계치에 따라 편향된 결과가 표면화될 수 있음을 저자들이 실험으로 보입니다. 활용 맥락에서 **윤리·사회적 영향**을 반드시 점검해야 합니다.

---

### 한 줄로 압축

거대한 웹 이미지–텍스트로 **대조학습**을 수행해, 자연어 프롬프트만으로 **제로샷 분류·전이**가 가능한 **범용 시각 표현**을 만든 것이 CLIP의 본질입니다. ImageNet 제로샷 76.2%, 분포 이동 강건성 향상, 간단한 프롬프트 엔지니어링 효과, 그리고 편향·윤리 이슈까지—방법은 단순하지만 파급력은 큽니다.