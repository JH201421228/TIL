# LIME

소유자: 주헌 박

# 한 줄 요약

블랙박스 모델의 개별 예측을 “근방(local)”에서 단순·해석 가능한 대리모델로 설명(LIME)하고, 대표 예시들을 중복 없이 골라서 모델 전반의 신뢰성까지 살피는 방법(SP-LIME)을 제안합니다.

# 왜 필요한가

- 사용자가 예측/모델을 신뢰하지 않으면 실제로 쓰지 않습니다. 신뢰는 개별 예측을 믿을 수 있는가(행동해도 될까)와, 모델을 배포해도 되는가(전반 신뢰)로 나뉘며, 둘 다 ‘왜 그런 예측이 나왔는지’를 이해할 때 높아집니다.

# 무엇을 제안하나

1. **LIME**: 어떤 분류기/회귀기든 상관없이, 설명하려는 입력 주변에서 해석 가능한 모델(선형·트리 등)을 학습해 “국소적으로 충실한” 설명을 제공합니다. 핵심 최적화는
    
    (\xi(x)=\arg\min_{g\in G} L(f,g,\pi_x)+\Omega(g)) 입니다. (여기서 (L)은 근방에서의 불일치, (\pi_x)는 가중 커널, (\Omega)는 설명 복잡도)
    
2. **SP-LIME**: 많은 샘플 중 **설명 다양성/대표성**을 극대화하도록, 설명 중요도 행렬 (W)와 가중 커버리지 (c(V,W,I))를 이용해 예시 (B)개를 고르는 **부분모듈러 최대화**(탐욕근사 (1-1/e))를 사용합니다.

# LIME은 어떻게 동작하나

- **해석 가능한 표현**: 텍스트는 단어 존재/부재, 이미지는 슈퍼픽셀 존재/부재 같은 사람 친화적 이진표현을 사용합니다. 본래 특징(임베딩 등)과 다를 수 있습니다.
- **국소 근사**: 입력 (x) 주변을 확률적으로 섭동해 표본을 만들고((x')의 일부만 켜기), 원 모델 (f)의 출력을 레이블로 받아, 거리 가중치 (\pi_x)로 **가중 최소제곱**의 희소 선형모델을 학습합니다.

# SP-LIME(요약)

- 각 샘플 설명의 특성 중요도를 모아 (W)를 만들고, 많이 등장하는 설명 요소일수록 전역 가중치 (I_j)를 크게 둡니다(텍스트는 (\sqrt{\sum_i W_{ij}})). 그런 다음 중복 없이 커버리지를 최대화하도록 (B)개 예시를 고릅니다.

# 주요 실험 결과

- **설명 충실도(시뮬레이션)**: 골드 기준(해석가능 모델의 진짜 중요 특성) 대비 LIME은 LR/DT 모두에서 **재현율 > 90%**로 높은 국소 충실도를 보였습니다.
- **모델 선택(시뮬레이션)**: 유효성 성능이 비슷하지만 일반화 성능이 다른 두 모델 중 **SP-LIME이 일관되게 더 잘** ‘더 나은 모델’을 골라냈습니다.
- **모델 선택(사람 실험)**: 20 Newsgroups로 학습한 SVM vs 헤더 등 문제 특성을 제거한 SVM을 비교할 때, 검증 정확도만 보면 잘못 고르기 쉽지만, **설명**을 보면 일반화가 더 좋은 모델을 선택할 수 있었습니다(“종교” 외부 데이터에서 57.3% vs 69.0%).
- **피처 엔지니어링(사람 실험)**: 비전문가가 설명을 보고 제거할 단어를 선택하는 것만으로, 외부 데이터 정확도를 라운드별로 끌어올렸고(SP-LIME이 RP보다 우수), 한 경로당 평균 **200개(SP)** 단어 제거, 라운드당 **평균 3.6분**만 투자해 개선했습니다.
- **“허스키 vs 늑대” 사례**: 눈 배경에 과적합된 나쁜 분류기에서, 설명을 본 후 대부분의 참가자가 **눈 배경**을 문제 원인으로 정확히 지목했고, 모델에 대한 **신뢰도도 하락**했습니다.

# 기존 접근과의 차별점

- 특정 아키텍처(주의/감지 기반)나 전역 근사(그래디언트/파르젠)와 달리, **모델 불문·국소 충실성**을 목표로 하며, 사람의 **인지 한계**를 아예 최적화 문제와 표현 설계에 녹였습니다.

# 결론

LIME은 블랙박스 예측을 **사람이 납득할 방식**으로 지역 근사해 설명하고, SP-LIME은 **대표 예시 묶음**을 뽑아 모델 전반을 빠르게 감별·개선하게 돕습니다. 텍스트/이미지에서 비전문가·전문가 모두에게 **신뢰 판단, 모델 선택, 피처 정리, 이상 징후 파악**에 유의미한 이득을 보였습니다.