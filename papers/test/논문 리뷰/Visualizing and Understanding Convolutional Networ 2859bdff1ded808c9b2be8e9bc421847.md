# Visualizing and Understanding Convolutional Networks

소유자: 주헌 박

- 이 논문은 합성곱신경망(CNN) 내부의 중간층을 “보는” 새 시각화 기법을 제안해, 어떤 입력 패턴이 어떤 특성맵(feature map)을 흥분시키는지 입력 픽셀 공간으로 되투영(deconvnet)해 보여주고, 이를 모델 설계·디버깅에 활용해 성능까지 끌어올립니다.
- 제안된 deconvnet은 (1) 맥스풀링 위치 스위치로 “언풀링”, (2) ReLU로 재정류, (3) 전치(뒤집은) 필터로 “역합성곱”을 수행해, 특정 활성화가 어디서 왔는지 단계적으로 복원합니다.
- 시각화 결과, 계층이 올라갈수록 특성이 더 추상화됩니다: 2층은 모서리·색 결합, 3층은 질감, 4층은 부분(개 얼굴·새 다리), 5층은 자세 변화가 큰 ‘객체 수준’ 패턴을 포착합니다.
- 변환 불변성 분석에서, 출력은 평행이동·스케일에 비교적 안정적이지만 회전에 대해서는 일반적으로 불변이 약합니다(대칭 물체 제외).
- “그레이 스퀘어” 가리개로 입력 일부를 가리며 민감도를 측정한 결과, 모델이 장면 맥락만이 아니라 실제 객체 위치에 민감하다는 것이 확증됩니다(가리면 해당 클래스 확률과 관련 특성맵 활성화가 크게 하락).
- 시각화로 드러난 문제(1층 필터가 중·저주파 덮개 부족, stride 4로 인한 2층 얼라이어싱)를 바탕으로 1층 필터를 11×11→7×7, 스트라이드를 4→2(1·2층)로 바꾸자 저층 표현이 더 깔끔해지고 성능도 개선됐습니다.
- ImageNet 2012에서 AlexNet 단일 모델을 앞서는 단일 모델을 얻었고, 앙상블로 테스트 Top-5 오류 14.8%를 기록해 당시 최고 성능을 달성했습니다.
- 제거(ablations) 실험에서 완전연결층(6,7층)만 뺀 영향은 제한적이지만, 중간 합성곱층을 크게 줄이고 깊이를 얕게 만들면 오류가 급증해 “최소한의 깊이”가 성능에 핵심임을 보였습니다.
- ImageNet에서 학습한 합성곱 특징을 “고정”하고 소프트맥스만 새로 학습하면 Caltech-101/256에서 최신 성과를 크게 앞지르며(예: Caltech-256 60장/클래스 설정에서 74.2% vs 55.2%), 소량 학습(one-shot 유사 설정)에서도 강력했습니다.
- 다만 PASCAL VOC 2012처럼 다객체·장면 중심 데이터에선 평균 성능이 최고 대비 약 3.2% 낮았지만, 여러 클래스에선 오히려 우세했습니다.

요컨대, 이 논문은 “보여주기(해석) → 고치기(설계) → 검증(성능·전이)”의 선순환을 촉발한 초기 해석 가능성 연구로, deconvnet 시각화·가림(occlusion) 민감도 분석으로 CNN이 무엇을 보고 결정하는지 드러내고, 그 통찰로 아키텍처를 실질적으로 개선해냈다는 점이 핵심입니다.