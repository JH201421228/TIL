# SqueezeNet

소유자: 주헌 박

# 무엇을 했나

- **SqueezeNet 제안**: AlexNet-level 정확도를 유지하면서 파라미터 수를 약 1.25M(≈4.8MB)로 축소. 동일 정확도 기준으로 **50×** 더 작음.
- **모델 압축과 결합**: Deep Compression(가중치 프루닝+정수화+허프만) 적용 시 **0.66MB(8-bit)**, 나아가 **0.47MB(6-bit)**까지 축소해도 AlexNet 수준 정확도 유지. 총 **510×** 축소.

# 왜 작은가(디자인 전략 3가지)

1. **3×3 대신 1×1 대거 사용**(파라미터 9배 절감),
2. **3×3에 들어가는 채널 수를 squeeze 층으로 먼저 줄이기**,
3. **다운샘플링을 뒤로 미뤄 큰 활성맵 유지**(정확도 유리).

# 어떻게 생겼나(구조)

- 기본 블록 **Fire 모듈**: `squeeze(1×1)` → `expand(1×1 + 3×3)` 조합. `s1x1, e1x1, e3x3`를 하이퍼파라미터로 노출.
- **네트워크**: `conv1` → `fire2–fire9`(점진적 채널 증가) → `conv10` → global avg-pool. Max-pool은 `conv1, fire4, fire8` 뒤에만(늦은 다운샘플링). FC층 없음.

# 결과(Imagenet-1k 기준)

- **SqueezeNet**: Top-1 57.5%, Top-5 80.3%, **4.8MB**. (AlexNet 240MB 대비 **50× 작음**)
- **압축 SqueezeNet**: 0.66MB(8-bit), 0.47MB(6-bit)에서도 AlexNet 수준 정확도 유지.

# 설계공간 탐색에서 얻은 통찰

- **Squeeze Ratio(SR)**: squeeze/expand 비율을 키우면 정확도 ↑, 하지만 모델도 커짐. SR=0.125(원본)→0.75로 올리면 Top-5가 **80.3%→86.0%**까지 상승(≈19MB) 후 포화.
- **1×1 대 3×3 비율(pct3x3)**: 3×3을 무작정 늘리면 모델은 커지지만 정확도 이득은 **50% 비율 근처에서 포화**.
- **매크로 설계(Residual 연결)**: 단순 바이패스를 Fire 3/5/7/9에 넣으면 **Top-1 +2.9p(57.5→60.4)**, **Top-5 +2.2p(80.3→82.5)**, **모델 크기 증가는 없음**. 복합 바이패스(1×1 conv 포함)는 크기↑에 비해 이득이 작음.

# 왜 중요한가(시사점)

- **분산 학습 통신량↓, OTA 업데이트 비용↓, 임베디드/FPGA 배치 용이**: 작은 모델은 훈련/배포/온칩 구현 모두에 실질적 이점을 준다. 실제로 10MB 미만 온칩 메모리에서도 전부 적재 가능해 대역폭 병목을 줄인다.

# 한 줄 정리

**많이 똑똑하게(1×1 적극 활용, squeeze로 3×3 입력 축소, 다운샘플링 지연) + 약간의 잔차 연결 = AlexNet급 정확도를 ‘USB 메모리 조각’ 크기로.**