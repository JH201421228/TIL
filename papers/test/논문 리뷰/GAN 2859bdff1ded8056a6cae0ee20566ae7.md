# GAN

소유자: 주헌 박

- **아이디어 한 줄 요약**: 생성기(Generator) G와 판별기(Discriminator) D를 서로 경쟁시키는 **적대적 학습**으로 데이터 분포를 배우게 한다. 이 게임은 미니맥스 최적화로 표현된다.
- **목표함수(게임의 규칙)**:
    
    (\min_G \max_D ; V(D,G) = \mathbb{E}*{x\sim p*{\text{data}}}[\log D(x)] + \mathbb{E}_{z\sim p_z}[\log(1 - D(G(z)))]).
    
- **최적의 판별기**: 생성기가 고정되면, 최적의 (D^*(x)=\frac{p_{\text{data}}(x)}{p_{\text{data}}(x)+p_g(x)}). 이때 생성기가 이 분포에 맞춰가면 판별기는 결국 어디서나 1/2를 내놓게 된다.
- **이론적 결론(언제 이긴 걸까?)**: 전역 최적점에서 (p_g=p_{\text{data}})이고, 목적함수 값은 (-\log 4). 이는 (-\log 4 + 2\cdot \text{JSD}(p_{\text{data}}|p_g))로 쓰여서, JSD가 0이 되는 지점이 곧 수렴점임을 보여준다.
- **학습 절차(현실 버전)**: D를 (k)번 업데이트하고 G를 1번 업데이트하는 식으로 번갈아 학습한다(논문 실험은 (k=1)). 초기엔 (\log(1-D(G(z))))가 포화되므로, G는 (\log D(G(z)))를 **극대화**하는 “non-saturating” 대체목표가 더 낫다.
- **왜 매력적일까**: 마르코프 체인(MCMC)이나 복잡한 추론 없이 **오직 역전파만**으로 학습·샘플링이 가능하다.
- **실험 한 컷**: MNIST, TFD, CIFAR-10에서 시연했고, Parzen 윈도우로 근사 로그우도 평가 시 MNIST에서 225±2의 수치를 보고했다(절대평가로 보기엔 한계가 있음을 스스로 언급).
- **한계와 주의점**: 명시적 (p_g(x))가 없고, G와 D의 **동기화 실패** 시 모드 붕괴(“Helvetica scenario”) 같은 문제가 생길 수 있다.
- **바로 확장 가능**: 조건부 생성(Conditional GAN), 보조 추론망, 준지도학습, 조건모델 패밀리 공유 등 다양한 확장이 자연스럽다.
- **한 문장 총평**: “GAN”은 생성모델 학습을 **판별 문제로 환원**해, 복잡한 추론을 건너뛰고 경쟁을 통해 데이터 분포에 수렴하도록 만든, 딥러닝 시대의 게임 체인저였다.