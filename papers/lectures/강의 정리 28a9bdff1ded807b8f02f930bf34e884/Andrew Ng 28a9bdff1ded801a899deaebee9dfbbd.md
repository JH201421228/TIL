# Andrew Ng

소유자: 주헌 박

## **2022년 머신러닝 스페셜라이제이션 (DeepLearning.AI & Stanford Online)**

### **큰 그림 (What/Why/How)**

- **Andrew Ng의 새로운 머신러닝 전문과정**으로, 2012년 Coursera 머신러닝 강의를 최신 내용으로 확장·재구성한 3개 코스 시리즈이다. **초보자 친화적 설계**로 직관적 시각 자료로 개념을 이해한 후, Python 코드를 통해 알고리즘 구현을 배우고, 이어서 선택적으로 수학적 원리까지 학습하도록 구성되었다.
- **무엇을 배우나?** 지도학습(선형 회귀, 로지스틱 회귀, 신경망, 결정 트리 등)과 비지도학습(클러스터링, 차원 축소, 추천 시스템 등) 전반을 폭넓게 다루고, **실리콘밸리 실무 모범사례**(모델 평가·튜닝, 데이터 중심 접근 등)까지 소개한다. 실습을 통해 **실제 AI 응용**에 모델을 구축해보는 경험도 제공하며, 머신러닝 분야로 커리어를 시작하려는 학습자에게 **체계적인 기초**를 마련해준다.

### **커리큘럼 구조 (코스별 주차별 내용)**

**Course 1: Supervised Machine Learning – Regression and Classification** (지도형 머신러닝 기초)

- **Week 1:** 머신러닝 개요와 핵심 개념을 소개한다. **지도학습 vs 비지도학습**의 차이, **회귀 vs 분류** 문제 정의를 배우고, 단일 변수 **선형 회귀** 모델을 구축해본다. 비용 함수 개념과 **경사하강법**을 통한 모델 학습 원리를 시각적으로 이해한다. 예를 들어, 한 개의 면적 특징으로 주택 가격을 예측하는 모델을 만들면서, 오차를 줄이기 위한 파라미터 업데이트 과정을 살펴본다.
- **Week 2:** 다수 입력 특성을 갖는 **다중 선형 회귀**로 확장한다. 다중 변수에서도 비용 함수를 최소화하는 **경사하강법**을 구현하고 수렴을 가속하기 위한 기법들을 익힌다 (학습률 선택, **특징 스케일링**, **다항 회귀**를 통한 특징 생성 등). 이를 통해 모델 성능 개선 방법론과 **학습곡선**을 해석하는 법을 배운다.
- **Week 3:** **로지스틱 회귀**를 활용한 **이진 분류**를 학습한다. 왜 분류 문제에 선형 회귀가 부적절한지 이해하고, 시그모이드 함수 기반의 로지스틱 모델이 **확률적 출력**으로 분류 결정을 하는 원리를 익힌다. 로지스틱 회귀의 비용 함수와 경사하강 최적화를 구현하고, **과적합(overfitting)** 문제를 소개한다. 이를 완화하기 위한 **정규화** 기법($L2$ 페널티)을 적용하여 모델의 일반화 성능을 높이는 법을 실습한다.

**Course 2: Advanced Learning Algorithms** (고급 학습 알고리즘)

- **Week 1:** **신경망 (Neural Network)** 기반 분류 알고리즘을 다룬다. 인간 뇌의 뉴런 개념에 비유하여 **퍼셉트론**으로 시작해 다층 신경망 구조를 소개하고, **순전파 알고리즘**으로 분류 예측을 수행하는 원리를 배운다. TensorFlow를 사용해 손글씨 숫자이미지 등의 **이진 분류 신경망**을 간단히 구축하고, 나아가 Python/NumPy로 **신경망을 처음부터 구현**하면서 행렬 연산(**벡터화**)을 통해 연산 효율을 높이는 법도 익힌다.
- **Week 2:** **신경망 학습** 심화 및 개선 기법을 학습한다. 다양한 **활성화 함수**(ReLU, tanh 등)의 필요성과 용도를 배우고, 이진 분류를 넘어 **다중 클래스 분류**로 확장한다. 이를 위해 **소프트맥스(Softmax)** 출력과 **교차 엔트로피 손실** 함수를 도입하고, TensorFlow로 숫자 이미지 **10개 클래스 분류** 신경망을 구현한다. 더 나은 최적화를 위해 **Adam 최적화 알고리즘** 등을 사용하여 경사하강보다 빠르게 수렴시키는 방법을 익힌다. 추가로, **다중 레이블 분류** 개념과 **심층 신경망의 추가 레이어 유형**(예: 합성곱층 등)을 간략 소개하여 현대 딥러닝으로의 길을 열어준다.
- **Week 3:** **머신러닝 프로젝트의 모범 사례**를 배운다. 데이터를 **훈련/검증/테스트 세트**로 분리해 모델 성능을 객관적으로 평가하는 방법, **모델 선정 및 하이퍼파라미터 튜닝** 기법을 다룬다. **편향-분산 트레이드오프**를 진단하고 (예: **학습곡선**으로 **언더피팅/오버피팅** 식별), 상황에 따른 해결책(모델 복잡도 조절, 데이터 양 증가, 특징 공학, 정규화 적용 등)을 논의한다. **데이터 중심 AI(Data-centric AI)** 개념을 소개하여 모델뿐 아니라 **데이터 품질 개선**(데이터 확장, 증강 등)이 성능 향상에 미치는 영향도 설명한다. 윤리적 문제(편향, 공정성)와 실전에서 흔한 오류 사례도 함께 다뤄 **현업 응용 감각**을 기른다.
- **Week 4:** **결정 트리** 및 **앙상블** 기법을 학습한다. 먼저 분류를 위한 **의사결정나무** 알고리즘을 배우는데, 정보 균일도를 나타내는 지표(엔트로피 또는 지니 불순도)를 기반으로 데이터를 분할하는 원리와 트리의 **과적합 제어**(가지치기 등)를 다룬다. 이어서 다수의 트리를 결합하는 **앙상블 방법**으로 **랜덤 포레스트**(배깅 기반)와 **부스팅**(예: XGBoost) 알고리즘의 개념을 익힌다. 서로 다른 모델 유형(신경망 vs 트리 계열)을 비교하며, **실제 문제 유형에 따른 모델 선택 전략**도 논의한다.

**Course 3: Unsupervised Learning and Recommender Systems** (비지도학습 및 추천 시스템)

- **Week 1:** **비지도 학습** 기법을 탐구한다. 우선 **클러스터링**의 대표 알고리즘인 **K-평균**을 구현하여, 레이블 없는 데이터에서 유사한 샘플들을 군집으로 묶는 방법을 배운다. 초기 중심 설정, 군집 할당 및 중심 재계산의 반복 과정을 통해 알고리즘이 수렴하는 원리를 이해하고, 적절한 클러스터 개수 선택에 대해 토의한다. 또한 **이상탐지(Anomaly Detection)** 기법을 소개하여, 정상 데이터의 확률 분포(예: 다변수 가우시안)를 학습하고 통계적으로 희귀한 패턴을 이상치로 판단하는 방법을 실습한다. 언제 **지도학습 대신 이상탐지**를 활용해야 효과적인지 판단하는 기준도 함께 논의된다. (*주*: 이 과정에서는 필요에 따라 **계층적 클러스터링**이나 **PCA**(주성분분석) 등의 차원 축소 기법도 부가적으로 다룰 수 있다).
- **Week 2:** **추천 시스템(Recommender System)**의 핵심 원리를 배운다. 먼저 **협업 필터링** 기법으로 사용자-아이템 **평점 행렬**을 분석해 **행렬 분해** 기반의 추천 알고리즘을 구현한다. 예를 들어, 사용자 선호도와 아이템 속성 벡터를 학습하여 사용자가 아직 평가하지 않은 아이템의 평점을 예측하는 방법을 실습한다. 이후 **콘텐츠 기반 추천**으로, 아이템의 속성이나 컨텐츠(예: 영화의 장르, 상품 설명)를 고려하는 추천 방법을 다룬다. 특히 **딥러닝을 활용한 콘텐츠 임베딩** 기법을 소개하여, 신경망이 사용자와 아이템의 특성을 벡터로 표현하고 유사도를 측정해 추천을 생성하는 **현대적 접근**도 경험한다.
- **Week 3:** **강화학습(Reinforcement Learning)**의 기초를 익힌다. 에이전트가 환경과 상호작용하며 **시행착오를 통해 학습**하는 개념을 설명하고, 간단한 문제에서 **심층 강화학습**을 구현한다. 구체적으로는 **딥 Q-네트워크(DQN)** 알고리즘을 배워, 상태를 입력받아 각 행동의 가치를 예측하는 신경망을 설계한다. 에이전트가 목표 보상을 극대화하도록 Q값을 업데이트하는 **Q-러닝 알고리즘**을 실습하고, 게임 등 시뮬레이션 환경에서 학습이 이루어지는 과정을 관찰한다. 이를 통해 모델기반 학습과 모델프리 학습의 차이, 탐험-이용 딜레마 등 강화학습의 핵심 개념을 체험적으로 이해한다.

### **주요 수식 및 구현 포인트**

- **선형 회귀**: 모델 가설 $h_\theta(x)=\theta^T x$ 형태로 표현되고, **비용 함수**로 평균제곱오차 $J(\theta)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$를 사용한다. 이 비용을 최소화하기 위해 모든 파라미터 $\theta$에 대해 **경사하강법** 업데이트 규칙 $\theta_j := \theta_j - \alpha \frac{\partial J}{\partial \theta_j}$를 적용하는데, 학습률($\alpha$) 선택에 따른 수렴 영향 등을 실습을 통해 체감한다. 수식의 의미를 그림으로 시각화하여 직관을 쌓은 후, Python/Numpy로 이를 구현하고 scikit-learn의 선형 회귀 결과와 비교하면서 이해를 확인한다.
- **로지스틱 회귀**: 시그모이드 함수 $\sigma(z)=\frac{1}{1+e^{-z}}$를 사용하여 출력값을 $0$과 $1$ 사이 확률로 변환한다. **로그 손실** 비용 함수 $J(\theta)=-\frac{1}{m}\sum_{i=1}^m \big(y^{(i)}\log h_\theta(x^{(i)}) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))\big)$를 도입하고, 이를 경사하강법으로 최소화하여 모델 파라미터를 학습한다. 이때 과적합을 방지하기 위해 비용 함수에 **정규화 항** $\frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$를 추가하며(편향 항 $\theta_0$는 보통 제외), **$\lambda$ 값에 따른 모델 복잡도 변화**를 실험해본다. 구현 면에서는, 수치적으로 불안정할 수 있는 로그함수 계산을 안전하게 처리하는 등 실제 프로그래밍 시의 고려사항도 다룬다.
- **신경망**: **다층 퍼셉트론** 구조에서 **순전파**는 각 층의 선형 조합과 비선형 활성화를 반복하며 진행된다 (예: 은닉층 뉴런 계산 $a^{(l+1)} = f(W^{(l)} a^{(l)} + b^{(l)})$). **역전파 알고리즘**은 출력층에서 시작해 체인룰을 따라 오차의 기울기를 전파하여 각 가중치의 **그래디언트**를 구한 뒤, 경사하강 업데이트로 가중치를 조정한다는 개념을 다룬다. 이 과정에서 **행렬 미분**과 같은 수학이 활용되지만, 코스에서는 TensorFlow의 자동미분으로 이를 간소화하여 구현한다. 대표적인 활성화 함수로 **ReLU** $f(z)=\max(0,z)$를 사용해 비선형성을 주입하고 **소프트맥스** $\sigma_{\text{softmax}}(z)_j = \frac{e^{z_j}}{\sum_k e^{z_k}}$로 다중클래스 확률출력을 만든다. **손실 함수**로는 교차 엔트로피를 사용하여 미분이 깔끔하게 떨어지도록 했다. 학습률 등 하이퍼파라미터 튜닝 외에도, **Adam 옵티마이저**의 모멘텀과 적응형 학습률 조정 공식을 학습하여 ($m_t, v_t$ 추적 등) 경사하강법 대비 효율적임을 확인한다. 신경망 구현 과제에서는 직접 파이썬으로 역전파까지 코딩하면서, 벡터화된 연산으로 **CPU 병렬화**를 극대화해 보는 것이 특징이다.
- **결정 트리 & 앙상블**: 결정 트리는 **재귀적 분할**을 통해 데이터를 분류하며, 수식적으로는 분할 기준으로 정보획득(Information Gain)을 최대화하는 특성을 선택한다. 정보획득 $\text{IG}(X,\text{split}) = H(\text{parent}) - \sum_k \frac{|N_k|}{|N|}H(N_k)$ (엔트로피 $H=-\sum_i p_i\log p_i$ 활용)을 최대화하는 분할을 찾는 과정을 거친다. 구체적인 수식 유도보다는 이러한 **지니 지수**나 **엔트로피** 개념을 이해하는 데 중점을 둔다. 트리가 너무 깊어져 과적합될 경우 **가지치기(pruning)**를 통해 복잡도를 줄이는 전략도 함께 다룬다. **랜덤 포레스트**는 여러 결정 트리 모델 $h_1(x), h_2(x), \dots$의 예측을 평균내거나 투표하여 최종 예측 $H(x)$를 산출하며, 각 트리는 데이터 부트스트랩 샘플 및 부분 특징 집합으로 학습해 **상관관계 감소** 및 성능 향상을 얻는다. **XGBoost** 등 **부스팅**은 잔여 오차를 줄이도록 순차적으로 약한 학습기를 추가하는 알고리즘으로, 트리가 학습하는 **잔차(residual)**에 대해 경사하강법을 적용하는 수식을 갖지만 상세 유도보다는 직관과 실용 효과에 집중한다. 최종적으로 신경망과 트리계열 모델의 장단점을 비교하며, **엔지니어링 관점**에서의 모델 선택 팁도 정리한다 (예: 데이터 크기나 해석 필요성에 따른 선택 등).
- **클러스터링 & 차원 축소**: K-평균은 군집 내 제곱거리 손실을 최소화하는 방식으로 정의되며, **객관식 함수** $J({c^{(i)}}, {\mu_k}) = \sum_{i=1}^m |x^{(i)} - \mu_{c^{(i)}}|^2$를 반복 최적화(배정 단계: $c^{(i)}:=\arg\min_k |x^{(i)}-\mu_k|$, 평균 단계: $\mu_k:=\frac{1}{|C_k|}\sum_{i\in C_k}x^{(i)}$)한다. 수렴 특성과 지역 최적해 문제 등을 토의하고, **엘보 방법**으로 적정 클러스터 개수를 정하는 경험적 방법도 언급한다. **PCA(주성분분석)**는 고차원 데이터를 저차원으로 투영하면서 **분산**을 최대로 보존하는 선형 변환을 찾는 기법으로, 공분산 행렬의 **고유분해** $Σ = PDP^{-1}$를 통해 **고유벡터**(주성분)와 **고유값**(분산 크기)을 구하는 수학적 절차를 다룬다. 구현시에는 SVD 라이브러리를 사용하지만, 수식적으로 데이터 행렬 $X$의 특잇값 분해 $X = U\Sigma V^T$로부터 PCA 결과를 얻는 방법을 설명한다. **EM 알고리즘**은 미완성 데이터의 우도함수를 최대화하기 위한 일반 해법으로, GMM(혼합 가우시안 모델) 학습에 적용된다. E-스텝에서 책임도 $\gamma_{zk} = \frac{\pi_k \mathcal{N}(x^{(z)}|\mu_k,\Sigma_k)}{\sum_{j}\pi_j \mathcal{N}(x^{(z)}|\mu_j,\Sigma_j)}$를 계산하고 M-스텝에서 모수 갱신 $\mu_k := \frac{\sum_z \gamma_{zk} x^{(z)}}{\sum_z \gamma_{zk}}$ 등의 수식을 사용해 반복 수행하는 원리를 배운다. 이러한 수학적 프레임워크를 통해 **군집화**와 **혼합 모델**이 실제 데이터의 잠재구조를 추정하는 방법을 이해한다.
- **추천 알고리즘**: **협업 필터링**에서는 사용자-아이템 행렬 $Y$의 알려진 평점에 대해 **행렬 인수분해**를 수행한다. 예컨대 사용자 특징 행렬 $U\in\mathbb{R}^{m\times r}$와 아이템 특징 행렬 $V\in\mathbb{R}^{n\times r}$를 찾아 $Y \approx UV^T$가 되도록 하는데, 이를 위해 **손실 함수** $J(U,V) = \frac{1}{2}\sum_{(i,j)\in \mathcal{R}}(Y_{ij} - u_i^T v_j)^2 + \frac{\lambda}{2}\left(\sum_i |u_i|^2 + \sum_j |v_j|^2\right)$를 경사하강법으로 최소화한다. 이 수식을 미분해 얻은 업데이트 식을 코드로 구현하고, 예측 성능을 **RMSE** 등으로 평가한다. **콘텐츠 기반 필터링**은 아이템의 특징 벡터(예: 영화 장르 원-핫 벡터 등)를 이용해 사용자 프로필과의 **코사인 유사도** 등을 계산하거나, 최신 기법으로 **신경망 임베딩**을 학습시켜 추천하는 방법을 다룬다. 예를 들어 영화 줄거리 텍스트로부터 **워드 임베딩**을 추출해 유사한 영화를 추천하는 등의 딥러닝 활용 아이디어도 소개된다.
- **강화학습**: **마코프 결정 프로세스(MDP)**의 구성요소(상태, 행동, 보상, 상태전이 확률, 할인율)를 정의하고, **벨만 방정식** $V^*(s) = \max_a \big[R(s,a) + \gamma \sum_{s'}P(s'|s,a)V^*(s')\big]$을 통해 최적 가치함수를 구하는 이론적 배경을 제시한다. 간단한 그리드 월드 예시로 **동적 프로그래밍** 방법인 **가치 이터레이션**과 **정책 이터레이션**을 수행해보고, 수식적으로 가치 이터레이션은 $V_{k+1}(s) := \max_a \big[R(s,a) + \gamma \sum_{s'}P(s'|s,a)V_k(s')\big]$ 형태의 업데이트임을 확인한다. 모델을 모르는 상황에서는 **Q-러닝**을 사용하며, **Q-값 업데이트 식** $Q(s,a) := Q(s,a) + \alpha\big[r + \gamma \max_{a'}Q(s',a') - Q(s,a)\big]$을 구현하여 에이전트가 반복 시도 끝에 최적 정책을 학습하게 만든다. 여기서 학습률 $\alpha$와 할인율 $\gamma$의 영향, $\epsilon$-탐욕 정책으로 **탐험-이용 균형**을 잡는 방법 등을 실험한다. **DQN**에서는 신경망 $Q(s,a;\theta)$을 두고 **손실 함수** $L(\theta) = \big(r + \gamma \max_{a'} Q(s',a'; \theta^-) - Q(s,a;\theta)\big)^2$를 미분하여 **오차역전파**로 파라미터 $\theta$를 업데이트하는 과정을 배운다. 이때 **타깃 네트워크** $\theta^-$, **경험 재생 메모리** 등 안정화 기법도 함께 소개된다. 비록 과정 전반에 걸쳐 상세한 수식 유도까지 요구되진 않지만, 핵심 알고리즘의 작동 원리를 뒷받침하는 이러한 **수학적 형태**를 접하며 이해도를 높이고자 한다.

### **실습/응용 사례**

- **프로그래밍 실습**은 Jupyter 노트북 환경에서 진행되며, **Python 기반의 머신러닝 라이브러리**들을 광범위하게 활용한다 (NumPy로 저수준 구현, **scikit-learn**으로 빠른 모델 적용, **TensorFlow/Keras**로 딥러닝 모델 구축 등). 각 주차별로 **미니 프로젝트** 형식의 과제가 있어, 학습한 이론을 실제 데이터셋에 적용해보게 된다.
    - 예를 들어 **코스 1**에서는 **선형 회귀** 실습으로 미국 도시별 인구와 식당 이익 데이터를 이용한 **단순 선형 회귀** 실험을 하거나, 다중 회귀로 여러 부동산 특성을 사용한 **주택 가격 예측**을 수행한다. 이어서 **로지스틱 회귀** 실습에서는 예시로 대학 입학시험 데이터로 합격 여부를 이진 분류하거나, 의료 검사 수치로 질병 유무를 예측하는 모델을 구현한다. 이러한 과정을 통해 **scikit-learn의 `LinearRegression`, `LogisticRegression`** 등과 **직접 구현한 모델**의 결과를 비교하며 라이브러리 활용법과 모델 내부동작을 함께 익힌다.
    - **코스 2**에서는 **손글씨 숫자(MNIST) 분류** 과제가 포함되어, **TensorFlow로 2-layer 신경망**을 구축해 숫자 이미지를 분류하고 정확도를 측정한다. 이후 동일한 네트워크를 **NumPy로 수동 구현**하여, 두 방식이 같은 결과를 내는지 검증하면서 딥러닝 프레임워크의 편의성을 실감한다. 또 다른 실습으로, **결정 트리**를 직접 구현하거나 scikit-learn의 **`DecisionTreeClassifier`**를 사용해 **신용카드 거래 데이터**를 분류해보고, **랜덤 포레스트**로 성능을 향상시켜보는 작업이 주어진다. 이 과정에서 트리 모델의 매개변수(깊이, 최소 샘플 수 등)를 바꿔가며 **튜닝 실험**을 진행하고 모델 복잡도와 성능의 관계를 체득한다.
    - **코스 3**의 실습에서는 **이미지 압축** 예제로 **K-평균 클러스터링**을 활용한다. 예컨대 컬러 이미지를 픽셀 색상값 공간에서 16개의 군집으로 묶어 팔레트를 축소하고, 압축 전후 이미지 품질을 비교해본다. **이상탐지** 실습으로는 서버 로그의 **네트워크 트래픽 데이터**에 가우시안 모델을 적용해 이상치 트래픽을 탐지하거나, 제조 공정 센서데이터로 장비 이상 여부를 판단해보는 프로젝트가 주어진다. **추천 시스템** 과제에서는 실제 영화 평점 데이터(예: MovieLens)를 이용해 **영화 추천**을 구현한다. 직접 구축한 협업 필터링 모델로 사용자의 미시청 영화 선호도를 예측하고, 인기 영화 기반의 베이스라인 방법과 **정확도(RMSE)**를 비교 평가한다. 나아가 딥러닝 기반 **콘텐츠 유사도 추천**(예: 영화 줄거리로 임베딩 학습)을 시도해보며 전통적 방법과의 차이를 토의한다. 마지막으로 **강화학습** 실습에서는 OpenAI Gym과 같은 시뮬레이션 환경(예: **CartPole 균형잡기** 등)에서 DQN 에이전트를 훈련시켜본다. 초기에는 랜덤하게 막대기가 넘어지던 에이전트가 학습을 통해 점차 균형 잡는 시간이 길어지는 것을 관찰하면서, **강화학습의 학습 동작**을 직접 확인할 수 있다.

---

## **스탠퍼드 CS229: 머신러닝 (Andrew Ng)**

### **큰 그림 (What/Why/How)**

- **CS229**는 Stanford 대학의 학부/대학원 수준 **기계학습 정규과목**으로, **머신러닝과 통계적 패턴 인식**에 대한 폭넓은 소개를 제공한다. Andrew Ng가 다년간 가르친 이 과목은 이론과 실제를 두루 갖춘 커리큘럼으로 명성이 높다. **무엇을 배우나?** 지도학습(판별모델과 생성모델), 비지도학습(클러스터링, 차원축소, 확률적 모델), **학습이론**(일반화 이론, 편향-분산 트레이드오프), **강화학습 및 최적 제어** 등 머신러닝의 핵심 주제들을 모두 다룬다. 각 주제는 **수학적 프레임워크** 위에서 엄밀히 다루어지며, 이론 유도와 알고리즘 이해에 초점을 맞춘다. 동시에, 로보틱 제어, 데이터 마이닝, 자율주행, 바이오정보학, 음성인식, 텍스트 웹 데이터 처리 등 **최신 응용 사례**들도 함께 소개되어 학생들이 배운 개념을 실세계 문제와 연결할 수 있도록 돕는다.
- **왜 배우나?** CS229를 수강함으로써 학생들은 머신러닝의 **큰 그림**과 알고리즘 간 상호 관계를 파악하게 된다. 예컨대, 같은 분류 문제도 **선형 모델**부터 **비선형 커널 SVM**, **신경망**에 이르기까지 다양한 방법으로 풀 수 있음을 배우고, 데이터 특성과 목표에 맞는 기법을 선택하는 안목을 기른다. 또한 **수학적 사고력**과 **문제해결 능력** 향상을 목표로, 알고리즘의 작동 원리를 증명과 과제로 직접 다뤄보며 **응용 능력**을 쌓는다. **How?** 강의는 주 2회 이뤄지며 문제 세트, 프로그래밍 과제, 그리고 팀별 프로젝트로 구성된다. 학생들은 이론 학습 → 과제 구현 → 프로젝트 응용의 단계를 통해 학습한 내용을 자기 것으로 만든다. CS229 수료 시에는 새로운 문제를 만나도 적합한 알고리즘을 **직접 설계하고 구현**할 수 있는 기초 역량을 갖추게 된다.

### **커리큘럼 (주차별 주요 주제)**

- **Week 1:** **머신러닝 소개** 및 기본 개념 설정. 머신러닝을 수식적으로 정의하고, **지도학습** 문제의 구성요소 (입력 $x$, 출력 $y$, 가설공간 $h_\theta$, 손실함수 등) 개괄. 첫 알고리즘으로 **선형 회귀**를 소개하여, 평균제곱오차 최소화 문제를 통해 모델 학습의 개념을 맛본다. 비용 함수 최소화를 위한 **정규방정식(Normal Equation)** 유도와 **경사하강법** 풀이를 모두 보여주며, 선형대수 및 미적분 활용을 복습한다. 이와 함께 **지도학습**과 대비되는 **비지도학습** 개념을 간략 언급하고, 수업/과제에 필요한 선형대수 기초(벡터·행렬 연산, 역행렬, 대각화)를 별도 섹션으로 복습한다[cs229.stanford.edu](https://cs229.stanford.edu/syllabus-autumn2018.html#:~:text=Lecture%C2%A02%209%2F26%20Supervised%20Learning%20Setup,Class%20Notes).
- **Week 2:** **로지스틱 회귀**와 **분류 문제**로 확장. 시그모이드 함수로 이진분류 결정경계를 도입하고, **최대우도 추정** 관점에서 로지스틱 회귀의 비용 함수를 해석한다. **뉴턴 방법**을 이용한 로지스틱 회귀 파라미터 최적화(이차 최적화 기법)를 소개하여 경사하강 대비 수렴 속도 비교한다. 또한 **퍼셉트론 알고리즘**을 다루어, 온라인 학습의 개념과 이진분류의 또다른 접근법을 보여준다. 이 시점에 **지수 가족 분포(Exponential Family)**와 **일반화 선형모델(GLM)** 이론을 소개하여, 로지스틱 회귀가 지수족의 특수한 경우임을 설명함으로써 나중에 다룰 소프트맥스 회귀 등으로의 이론적 확장을 준비한다.
- **Week 3:** **생성모델 vs 판별모델** 학습으로 분류 접근법의 철학을 비교한다. **가우시안 판별분석(GDA)**를 배워, 클래스 조건부 분포를 가정하고 베이즈 결정이론을 적용한 분류를 해본다. 이어서 **나이브 베이즈** 분류기를 학습하여, 조건부 독립 가정 하에서의 확률적 예측을 구현한다. 실제 텍스트 분류 예시(스팸 필터 등)에 나이브 베이즈를 적용하며, **라플라스 스무딩**으로 희소 데이터 문제를 해결하는 기법도 다룬다. 마지막으로 **서포트 벡터 머신(SVM)** 이론을 도입해 본격적인 **최적화 기반 판별모델**을 탐구한다. SVM의 **최대 마진 원리**를 설명하고, **힌지 손실** 개념 및 **하드마진/소프트마진** SVM의 수학적 정의를 제시한다. 이를 **이차형식 제한최적화(QP)** 문제로 표현하고(라그랑주 승수, KKT 조건 언급), 직관적으로는 결정경계를 가장 넓게 확보하는 해를 찾는 것임을 이해시킨다.
- **Week 4:** **커널 SVM** 및 **모델 평가 이론**. SVM에 **커널 트릭**을 적용하여, 입력공간에서 선형적으로 분리되지 않는 데이터를 **고차원 특성공간**으로 매핑해 선형분리가 가능하게 만드는 기법을 배운다. **RBF 커널** 등 대표 커널함수들을 소개하고, 커널함수 만족 조건(머셔 조건) 개념도 언급한다. SVM의 실전 적용 팁(커널 및 매개변수 선택 등)을 논의한 후, 전체 지도학습 모델들에 공통적으로 적용되는 **이론적 성능 평가** 개념을 다룬다. **편향-분산 트레이드오프**를 공식적으로 정의하고, 모델 복잡도와 훈련/테스트 오차 관계를 분석한다. **정규화**(가중치 감쇠 등)와 **교차검증**을 활용한 **모델 선택** 기법을 소개하여, 주어진 데이터에 **일반화가 잘 되는 모델**을 선택하는 과정을 학습한다. Andrew Ng가 강조하는 **머신러닝 실전 조언** (예: 많은 특징 중 어떤 것을 추가/제거할지, 데이터 부족 시 대처법, 오류 분석을 통한 원인 진단)을 이론 강의와 별도로 정리한 자료로 제공하고, 질의응답을 통해 **노하우**를 전달한다.
- **Week 5:** **결정 트리 & 앙상블 기법** + **Neural Networks (기초)**. 먼저 **결정 트리** 학습 알고리즘(CART)을 자세히 살펴본다. 정보 이득 계산을 통한 최적 분할 선택, 연속형 특징 처리(분할 임곗값 찾기), **과적합 방지**를 위한 가지치기(pruning) 등 트리 모델의 핵심을 다룬다. 또한 단일 트리의 단점(높은 분산)을 보완하는 **앙상블** 방법들을 소개한다. **배깅(Bagging)** 기법의 일환인 **랜덤 포레스트**를 통해 여러 무작위 트리의 투표가 어떻게 분산을 낮추는지 학습한다. **부스팅(Boosting)** 개념도 도입하여, **AdaBoost** 알고리즘으로 결정 stump들을 연쇄적으로 학습시키는 과정을 설명하고, 부스팅이 편향을 낮추는 효과를 보여준다. 이어서 새로운 장으로 **신경망**을 소개한다. 단층 퍼셉트론이 XOR 문제를 풀지 못하는 한계를 상기하며 **은닉층**을 가진 다층 신경망이 등장한 배경을 설명한다. **순전파**를 통해 입력에서 출력으로 계산이 진행되는 메커니즘을 배우고, 간단한 예제로 논리게이트 등을 신경망으로 구현해본다. 이 강의에서는 주로 신경망의 구조와 **표현력**에 초점을 맞추고, 학습 알고리즘은 다음 주에 다룬다.
- **Week 6:** **Neural Networks (학습)** 및 **실용적 팁**. 신경망의 **역전파(Backpropagation)** 알고리즘을 상세히 배운다. 각 층에서의 오류 역전파 수식 유도, **체인 룰**을 통한 기울기 계산 과정을 이해하고, 이를 이용해 **경사하강법으로 가중치 업데이트**하는 절차를 익힌다. (실제로는 행렬 미분을 이용한 벡터화된 공식을 사용함을 보여주고, 수동 계산은 소규모 예제로 개념만 익힌다.) 심층 신경망 훈련 시 발생하는 **Vanishing/Exploding Gradient** 문제 등도 이론적으로 언급하고, 현대 딥러닝에서 사용하는 해결책들(가중치 초기화, 정규화 기법, 배치 정규화 등)을 소개한다. 이 시점에서 **딥러닝**이라는 용어와 함께 합성곱 신경망이나 LSTM 등 **특수 구조**에 대한 선택적 소개자료가 제공될 수 있다. 주 후반에는 지금까지 배운 지도학습 기법들에 대해 **종합적인 실용 조언**을 정리한다. 예를 들어, 데이터 세트가 작으면 고분산 모델 대신 **판별적 선형모델**을 우선 시도, 특징 수가 매우 많으면 **정규화 강한 모델(예: L2 정규화 로지스틱)** 선호 등, 경험적 지침을 전달한다. 또한 중간 고사 또는 퀴즈 등을 통해 전반부 내용을 복습·평가한다.
- **Week 7:** **비지도학습 I – 군집화 및 혼합 모델**. **K-평균 클러스터링**을 심도 있게 다루며, 초기화에 따른 다른 결과, 지역 최적해 문제 등을 토론한다. 클러스터링의 응용(예: 고객 세그멘테이션, 이미지 양자화 등)을 소개하여 활용 분야를 보여준다. 이어서 **혼합 가우시안 모델(Gaussian Mixture Model)**로 확률적 클러스터링을 배운다. GMM에서는 각 클러스터를 가우시안 분포로 모델링하고, **EM 알고리즘**을 사용해 모수들을 추정한다는 점을 강조한다. EM 알고리즘의 E단계/M단계 수식을 유도하고, 직관적으로는 클러스터 소속의 **확률적 추정**과 **모수 재추정**을 번갈아 수행함을 이해한다. 혼합모델이 K-평균보다 풍부한 표현력을 가지나 계산비용이 높고 **수렴보장**이 어렵다는 현실적 고려사항도 언급한다.
- **Week 8:** **비지도학습 II – 차원 축소 기법**. 먼저 **주성분 분석(PCA)**을 학습한다. PCA의 목표인 **분산 극대화 방향 찾기**와 **재구성 오차 최소화** 관점 두 가지를 설명하고, 둘이 동일한 해를 줌을 수학적으로 보인다. 공분산 행렬의 **고유값 문제**를 풀어 주요 성분을 구하는 절차를 유도하고, 주성분들이 직교하며 분산 크기 순으로 정렬된다는 사실을 보여준다. 얼굴 이미지 데이터 등을 예로 들어 **차원 축소 후 시각화**하거나 노이즈 제거 효과를 확인한다. 다음으로 **독립 성분 분석(ICA)**을 소개하여, 신호 분리(blind source separation) 문제에서 사용되는 고급 기법을 맛본다. 예를 들어 여러 마이크 녹음에서 서로 다른 사람이 말하는 소리를 분리하는 **칵테일 파티 문제**에 ICA를 적용하는 데모를 보일 수 있다. 이밖에 **요인 분석(FA)**처럼 통계적 잠재요인 모델도 언급하며, PCA와의 차이를 설명한다. 이로써 비지도학습 기법들이 데이터의 숨겨진 구조를 어떻게 찾는지 비교 정리한다.
- **Week 9:** **강화학습 I – MDP와 동적 프로그래밍**. 순차적 의사결정 문제를 다루는 강화학습의 수학적 토대를 소개한다. **Markov Decision Process**의 정의 (상태, 행동, 보상, 상태전이 함수, 할인율)을 명확히 하고, **정책(policy)**과 **가치함수(value function)** 개념을 배운다. **벨만 최적방정식**을 제시하여 최적 가치함수 $V^*(s)$가 충족해야 하는 조건을 이해하고, 이를 푸는 방법으로 **가치 이터레이션** 알고리즘을 도출한다. 작은 그리드월드 예제를 통해 초기 가치 추정에서 시작해 반복 갱신으로 최적 가치에 수렴하는 과정을 보여준다. 또한 **정책 이터레이션** 방법도 다루어, 정책 평가와 정책 개선을 교차로 수행하면 최적 정책에 도달함을 확인한다. 고급 주제로 **LQR(선형 이차 조절)** 및 **LQG(선형 이차 가우시안)** 같은 고전 제어 이론도 언급하여, 연속 상태·행동 공간에서 해석적으로 풀 수 있는 경우를 소개한다.
- **Week 10:** **강화학습 II – Q-learning과 정책 탐색**. 모델 없는 강화학습의 대표 알고리즘인 **Q-러닝**을 공부한다. 환경의 모형을 알 수 없을 때 에이전트가 경험을 통해 **Q함수**(상태-행동 가치)를 학습하며, **오프-폴리시 학습** 특성과 수렴 보장(학습률 조건 하)을 설명한다. Q-러닝의 업데이트 식과 **탐험(ε-탐욕 정책)** 전략을 구현 수준으로 다루고, 학습이 수렴하면 최적 정책을 추출할 수 있음을 보인다. 함수 근사 방법으로 **딥러닝을 접목한 DQN** 개념을 소개하고, 대표적인 성과로 Atari 게임에서의 인간급 성능 달성을 간략히 언급한다. 마지막으로 **정책 기반 강화학습**으로 **REINFORCE 알고리즘**(정책 경사법)을 배우고, **배치 vs 온라인**, **부분 관측 문제(POMDP)** 등의 심화 주제를 개관한다. 학기 말에는 **최신 주제 소개 또는 종합 정리**로 강의를 마무리한다. 예컨대 딥러닝의 발전으로 전통 ML과 달라진 점이나, AI 윤리 등 **ML에 대한 비판적 시각**을 토론하며 균형 잡힌 견해를 제시한다.

### **수학적 프레임워크 및 핵심 공식**

- **수학적 배경:** CS229 수강에는 대학 수준의 **선형대수, 확률, 통계, 멀티변수 미적분** 지식이 전제된다. 강의 내용 전반에서도 이러한 **수학적 프레임워크**를 계속 활용하여 이론을 전개한다.
    - **최적화 이론:** 머신러닝 알고리즘 학습은 대부분 **최적화 문제**로 표현된다. 예를 들어 선형/로지스틱 회귀는 **경사하강법**으로 비용 함수를 최소화하고, 뉴턴 방법을 통해 2차 미분(헤시안)을 이용한 최적화도 소개된다. SVM의 학습은 **볼록 최적화** 문제로 공식화되며, 라그랑주 승수를 통한 **쌍대 문제** 해법과 **KKT 조건**도 강의 노트에서 다룬다. 이러한 수학 도구들을 사용해, 각 알고리즘의 해가 **글로벌 최적해**임을 증명하거나 수렴 속도를 분석한다. 또한 결정 트리의 최적 분할, 신경망의 역전파 등도 결국 **최적화 관점**에서 해석하며, SGD(확률적 경사하강) 등의 변형 기법도 이론적으로 언급한다.
    - **확률/통계:** 생성모델 (예: GDA, 나이브베이즈, GMM)에서는 **확률 분포**와 **베이즈 정리**가 핵심이다. 가우시안 판별분석은 공분산이 공통일 때 판별경계가 이차 형식으로 된다는 것을 **통계적 가정**으로부터 유도한다. 나이브베이즈는 특징 독립 가정하에 사후확률을 계산하며, 이때 **사전분포** 개념과 **MLE(최대우도추정)**, **MAP추정** 등을 다룬다. EM 알고리즘에서는 **완전데이터 우도**와 **Q함수** 개념, Jensen의 불평등을 활용한 우도 증가 증명을 통해 알고리즘 수렴을 논한다. 강화학습에서도 **확률론**이 토대가 된다. MDP의 상태 전이, 보상 기대값이 모두 확률적 개념이고, Q-러닝 수렴 증명에 **마르코프 연쇄** 이론이 등장한다. 따라서 확률분포의 성질, 기댓값과 분산, 불평등 정리(Hoeffding 등)** 등의 이론이 적재적소에 활용되어 알고리즘의 **일반화 성능**과 **수렴 보장**을 뒷받침한다.
    - **선형대수:** 선형대수는 ML 이론 전반에 깔려 있다. 선형 회귀의 정상방정식 해법은 $(X^TX)\theta = X^Ty$로 나타나며, **역행렬**이나 **유사역행렬** 개념으로 해를 표현한다. PCA의 본질은 공분산 행렬의 **고유분해** 문제이고, SVD를 통한 차원축소 구현으로 이어진다. 커널 방법에서는 **특징 맵 $\phi(x)$**에 의한 고차원 내적을 커널함수 $K(x,z)=\langle \phi(x),\phi(z)\rangle$로 대체함으로써, 암묵적으로 **고차원 공간에서의 선형 연산**을 수행한다. 신경망의 순전파와 역전파도 결국 벡터와 행렬 연산의 조합이며, **Jacobian** 행렬을 통한 미분으로 요약된다. 이렇듯 CS229는 각 알고리즘의 밑바탕에 있는 수학적 구조를 강조하여, 수강생들이 **공식의 의미**를 정확히 짚고 넘어가도록 한다.
- **주요 공식 예시:** 강의 노트와 슬라이드에는 각 주제마다 중요한 공식들이 등장한다. 예를 들어, **로지스틱 회귀**의 결정경계는 $h_\theta(x)=0.5$일 때 $\theta^T x=0$이라는 식으로 표현되고, **SVM**의 최적화 문제는 프라이멀 형태 $\min_{\mathbf{w},b} \frac{1}{2}|\mathbf{w}|^2 \text{ s.t. } y^{(i)}(\mathbf{w}^T x^{(i)}+b)\ge 1$로 제시된다. **라그랑주 듀얼**로 전환하면 $\max_\alpha \sum_i \alpha_i - \frac{1}{2}\sum_{i,j}\alpha_i\alpha_j y^{(i)}y^{(j)}\langle x^{(i)},x^{(j)}\rangle$ 꼴이 되며, 여기서 커널 $K(x^{(i)},x^{(j)})=\langle x^{(i)},x^{(j)}\rangle$를 치환 적용한다는 논의를 전개한다. **신경망 역전파**에서는 2-layer 네트워크를 예로 들면 출력층 오류 $\delta^{(2)} = a^{(2)} - y$, 은닉층 오류 $\delta^{(1)} = (W^{(1)})^T \delta^{(2)} \circ f'(z^{(1)})$ 등의 식을 보여주며, 이를 통해 가중치 그래디언트 $\nabla_{W^{(1)}} = \delta^{(2)}(a^{(1)})^T$를 구하는 과정을 설명한다. **PCA**의 핵심 공식은 공분산 $Σ = \frac{1}{m}\sum_{i=1}^m (x^{(i)}-\mu)(x^{(i)}-\mu)^T$의 고유값 분해 $Σ = W \Lambda W^T$이며, 최상위 $k$개의 고유벡터 $W_k$가 투영 행렬이 되어 차원 $k$로 축소함을 수식으로 나타낸다. **강화학습**에서 중요한 벨만 방정식은 앞서 언급한 바와 같이 $V^*(s)$나 $Q^*(s,a)$에 대한 재귀식으로 주어지며, 최적 정책 $\pi^*(s) = \arg\max_a Q^*(s,a)$를 도출하는 공식으로 이어진다. 이러한 공식들은 CS229의 **이론적 깊이**를 상징하며, 학생들은 이를 통해 머신러닝 알고리즘이 **어떤 목적함수를 최적화**하고 **어떤 제약 조건을 만족**하는지 명확히 이해하게 된다.

### **과제 및 실습 예시**

- **과제 (Problem Sets):** 이론 강의와 병행하여 4회 가량의 문제 세트(필기 및 계산 과제)가 주어진다. 여기에는 수식 유도, 이론 증명, 알고리즘 변형 등이 포함되며, 예를 들어 **SVM 듀얼 문제 유도**, **퍼셉트론 수렴성 증명**, **EM 알고리즘 과정 계산**, **신경망에서의 그래디언트 검산** 등이 출제된다. 또한 일부 문제는 간단한 코딩을 포함하여, 주어진 데이터를 가지고 수식에서 도출한 알고리즘을 **직접 구현**해 결과를 확인하도록 한다. 예컨대 **Problem Set 1**에서는 **선형 회귀**와 **로지스틱 회귀**를 수식으로 풀어보고, 이를 소규모 데이터셋에 적용하는 코딩 문제가 포함될 수 있다. **Problem Set 2**는 **SVM과 이상치 탐지** 등을 다루면서, 커널 SVM의 서포트 벡터 개념을 시각화하는 실습을 할 수도 있다. **Problem Set 3**는 **비지도학습** 테마로, K-평균 클러스터링 수작업 계산, PCA 차원축소 구현 등의 과제가 포함된다. **Problem Set 4**는 **강화학습**에 관한 문제들로, 작은 MDP에서 가치 이터레이션 수작업 계산, Q-러닝 에피소드 추적 등이 출제될 수 있다. 이러한 문제 세트는 난이도가 높지만, 학생들이 **핵심 개념을 수학적으로 숙지**하고 직접 풀어봄으로써 깊이 있는 이해를 돕는다.
- **프로그래밍 실습:** CS229에는 별도의 **프로그래밍 과제**도 존재한다. 역사적으로 Andrew Ng의 Coursera 머신러닝 과제들이 CS229의 프로그래밍 과제와 유사하며, 최근에는 파이썬으로 리뉴얼되어 제공된다. 예를 들어 **과제 EX1**에서는 Octave/MATLAB 또는 Python으로 **선형 회귀**를 구현해보며 경사하강법이 수렴하는지를 출력으로 확인한다. **EX2**에서는 **로지스틱 회귀**로 **마이크로칩 테스트 데이터 분류** 실습을 하는데, 결정경계를 그려보고 정규화 효과를 실험한다. **EX3**에서는 **다중 클래스 분류와 신경망 전방통과**를 다뤄, 손글씨 숫자 (0–9) 데이터에 **로지스틱 회귀 (일대다)**를 적용하고, 제공된 신경망 가중치를 이용해 예측을 수행하는 연습을 한다. **EX4**에서는 **신경망 학습** 과제로, 앞의 숫자 분류 문제에 직접 역전파 알고리즘을 구현해 가중치를 학습시켜본다. **EX5**는 **편향-분산** 실험으로, 다항 회귀를 이용해 **과적합 현상**을 관찰하고 **교차검증**으로 최적 다항 차수를 선택하는 내용이다. **EX6**는 **SVM을 이용한 스팸 이메일 분류기** 실습으로, 이메일 데이터의 **텍스트 전처리**(단어 빈도 특징 추출)부터 SVM 훈련까지 수행하여 분류 정확도를 측정한다. **EX7**은 **K-평균과 PCA** 실습으로, 컬러 이미지 압축에 K-평균을 적용하고 얼굴 이미지 데이터에 PCA로 특징 추출을 해본다. **EX8**은 **이상감지와 추천** 실습으로, 서버 활동 로그의 이상치를 Gaussian 모델로 잡아내보고, 영화 평점 행렬에 협업필터링을 적용해 영화 추천을 구현한다. 이처럼 프로그래밍 과제들은 실질적인 데이터 처리와 알고리즘 구현 능력을 길러주며, CS229 수강생들은 **Matlab/Octave** 뿐만 아니라 **Python/numpy** 활용에도 능숙해지게 된다 (최근엔 Python 사용 권장이 높아, 보조 세션으로 Python 사용법도 제공된다[cs229.stanford.edu](https://cs229.stanford.edu/syllabus-autumn2018.html#:~:text=,21)).
- **팀 프로젝트:** CS229의 백미는 학기 말 **오픈엔드 팀 프로젝트**이다. 2~3인 한 조가 되어 자유 주제로 프로젝트를 수행하는데, **새로운 데이터를 수집**하여 직접 모델을 적용해볼 수도 있고, 특정 논문의 **기법을 구현 및 개선**해볼 수도 있다. 프로젝트 주제는 매우 다양하며, 예를 들어 **의료영상 데이터**로 질병을 예측하는 딥러닝 모델, **자연어 처리**를 통한 트위터 감성 분석, **강화학습**으로 간단한 로봇 제어, **추천 시스템** 고도화 등 **최신 ML 응용**을 다룰 기회가 된다. 학생들은 프로젝트 제안서 제출 → 중간 결과 (포스터 혹은 보고서) 제출 → 최종 보고서 및 포스터 발표의 과정을 거치며, **연구 사이클**을 직접 경험한다. Andrew Ng와 TA들은 중간중간 피드백을 주고 방향성을 잡아주며, 최종 발표 때는 모든 팀이 모여 포스터 세션을 통해 서로의 결과를 공유한다. 뛰어난 프로젝트들은 수업 이후 **논문으로 발전**시키거나, 스타트업 아이디어로 이어지는 경우도 있다. 전체적으로 CS229 프로젝트를 통해 학생들은 **창의적으로 문제를 정의**하고 **자율적으로 해결책을 탐색**하는 능력을 기르며, 강의에서 배운 이론을 한층 심화된 실제 문제에 적용해 보는 귀중한 경험을 쌓는다.

**참고 자료:** Andrew Ng의 CS229 강의노트와 Coursera 과제 내용, 그리고 DeepLearning.AI 머신러닝 스페셜라이제이션 가이드 등을 기반으로 정리하였다.