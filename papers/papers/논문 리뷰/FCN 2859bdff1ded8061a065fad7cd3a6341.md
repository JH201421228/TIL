# FCN

소유자: 주헌 박

- **문제와 한 줄 핵심**: 분류용 CNN을 “완전 합성곱(fully convolutional)”으로 바꿔 입력 크기와 상관없이 **픽셀 단위(segmentation) 예측**을 end-to-end로 학습·추론한다. 별도 전처리/후처리 없이도 당시 최고 성능을 달성했다.
- **아이디어 1 — 분류 CNN의 ‘합성곱화’**: 완전연결층(FC)을 “커널이 입력 전체를 덮는 1×1/대형 합성곱”으로 해석해 **공간적 점수 맵(heatmap)**을 직접 출력하게 만든다. 겹치는 수용영역을 한 번에 처리하므로 패치 슬라이딩보다 훨씬 효율적이다.
- **아이디어 2 — 업샘플링(Deconvolution) 레이어**: 다운샘플로 거칠어진 출력을 **네트워크 안에서 역방향 합성곱(“deconv”)**으로 학습적으로 업샘플링해 픽셀 해상도로 끌어올린다(고정 bilinear도 가능).
- **아이디어 3 — Skip 구조(FCN-32s/16s/8s)**: “깊고 거친 의미”와 “얕고 세밀한 외형”을 **계층 간 합(스킵 연결)**으로 결합해 경계·세부가 선명한 마스크를 만든다. stride 32→16→8로 갈수록 정밀도 향상(FCN-32s→16s→8s).
- **효율성 vs 대안 비교**:
    - OverFeat의 **shift-and-stitch**(입력 시프트+출력 인터레이스)는 이론적으로 **필터 희박화**와 동등하나, 정보 접근 한계를 남긴다. 본 논문은 학습형 업샘플링이 더 효과적·효율적이라 결론.
    - **패치 학습** 대신 **전(全) 이미지 학습**이 수렴 속도·벽시계 시간에서 유리하고 성능도 동일함을 실증.
- **전이학습(Transfer) 전략**: AlexNet, VGG16, GoogLeNet 분류 모델을 FCN으로 바꾼 뒤 **미세조정(fine-tuning)**하여 세그멘테이션에 전이. 별도 슈퍼픽셀/제안영역/CRF 없이 동작.
- **정량 결과(당대 SOTA)**:
    - **PASCAL VOC 2012 test**: **62.2% mIoU**, 약 **175 ms**/이미지 추론(20% 상대 개선).
    - **NYUDv2**: RGB-HHA late-fusion + stride 16으로 **mIoU 34.0%**.
    - **SIFT Flow**: 멀티태스크(의미+기하)로 **클래스 mIoU 39.5%, 기하 픽셀 정확도 94.3%**.
- **메트릭 통찰**: mIoU는 **미세 경계 정확도**에 둔감할 수 있음—다운샘플링된 GT를 업샘플링해도 높은 mIoU 상한이 가능(예: stride 32에서도 86.1%).
- **의의**: 분류 CNN을 FCN으로 재해석하고, **업샘플링+스킵 결합**이라는 간결한 설계로 이후 U-Net/FPN/DeepLab류의 **표준 설계 문법**을 여는 기초를 놓았다. 복잡한 파이프라인 없이도 **단일, end-to-end** 모델로 고속·고성능 세그멘테이션이 가능함을 보여줌.
- **한계/후속 과제(암시)**: stride를 무리하게 줄이면 학습이 어려워지고 계산량이 급증(예: VGG16 상단 대형 커널). CRF 같은 정교한 후처리 없이도 좋지만, 더 미세한 경계 복원에는 추가 기법이 유용할 여지.