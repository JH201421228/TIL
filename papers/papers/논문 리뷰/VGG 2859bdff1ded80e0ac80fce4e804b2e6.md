# VGG

소유자: 주헌 박

# 무엇을 했나

- **핵심 아이디어**: “필터는 **작게(3×3)**, 네트워크는 **깊게(16–19층)**.” 이 단 하나로 ImageNet SOTA급 정확도를 찍었다.
- **연구 질문**: 깊이를 늘리면 진짜 정확도가 오르나? → **YES**. 동일한 설계에서 **깊이만** 늘려가며 정량 증명.

# 왜 3×3인가

- **표현력**: 7×7 한 층 대신 **3×3 × 3층**은 ReLU가 3번 → 더 복잡한 결정 경계.
- **파라미터**: 7×7(C→C)=**49C²**, 3×3×3=**27C²** → 약 **45%**만 사용(= 55% 절감).
- **수용영역**: 3×3×k를 쌓으면 유효 수용영역이 커져 큰 필터 효과를 누적 달성.

# 구조 요약(가장 전형: VGG-16/19)

- 입력 **224×224 RGB**, 평균 감산만 전처리.
- Conv 블록: **3×3, stride 1, same padding**, 채널은 **64→128→256→512**로 MaxPool 뒤 배로 증가.
- 풀링: **2×2, stride 2**를 총 **5회**.
- 분류 헤드: **FC 4096 → FC 4096 → FC 1000** + Softmax.
- 변형: 일부 구성에서 **1×1 Conv**도 사용(채널 혼합), 하지만 전반적으로 **3×3 일관성**이 더 강했다.

# 학습/테스트 레시피

- **SGD + Momentum 0.9**, **L2=5e-4**, **Dropout 0.5(FC)**, step형 LR 스케줄.
- **데이터 증강**: 랜덤 크롭, 좌우 반전, 색상 변형.
- **스케일 전략**: 학습 시 **Scale Jittering(S∈[256,512])** → 강건성↑.
- **테스트**: FC→Conv로 바꿔 **Dense 평가**(전 이미지 슬라이딩), **멀티스케일/멀티크롭**과 **TTA(좌우반전)** 결합.

# 성능(요지)

- 깊이 ↑ → 오차 ↓, **19층**에서 포화.
- **3×3로만 쌓은 모델**이 1×1을 많이 섞은 동심층보다 우수(공간 문맥 보존이 관건).
- 단일/앙상블 모두 당시 최상위권 ImageNet 성능.

# 왜 중요한가(의의)

- “**작고 깊게**”라는 간명한 설계 원리를 **실험으로 정식화**.
- **백본(backbone)의 표준**: 분할·검출·행동인식 등에서 특징 추출기로 광범위하게 재사용.
- **전이학습 시대 개막**: 파인튜닝 없이도 4096-D 특징이 다른 데이터셋에서 SOTA급.

# 한계/교훈

- **파라미터/연산량 큼**(특히 FC 4096×2가 무거움) → 학습/추론 느림, 메모리 큼.
- **잔차 연결(ResNet)** 같은 학습 보조 없이 더 깊게 쌓기 어렵다.
- 교훈: 단순성 + 일관성 + 데이터/증강/테스트 레시피의 합이 SOTA를 만든다.

# 실무 체크리스트(요약 적용)

- **설계**: 3×3 Conv 블록을 2–3층씩 쌓고, 해상도는 MaxPool로만 줄여 초기 정보 보존.
- **규제**: 작은 필터 누적 자체가 규제 효과, L2/Dropout로 과적합 추가 억제.
- **배포**: 정확도 최우선 연구용엔 여전히 강력한 기준선, **경량/실시간**이 목표면 MobileNet/ResNet 계열 고려.

한 문장으로: **VGG = 3×3을 끝까지 밀어붙여 “작고 깊게” 만든, 단순하지만 강력한 범용 시각 백본**.