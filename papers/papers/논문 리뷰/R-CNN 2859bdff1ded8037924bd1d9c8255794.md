# R-CNN

소유자: 주헌 박

# 한눈에 보는 한줄 요약

**“좋은 후보영역을 먼저 고르고(CPU/SS로 약 2천개), 각 후보를 CNN에 넣어 4096D 특징을 뽑은 뒤, 클래스별 선형 SVM으로 점수화 + NMS + 박스회귀로 좌표 보정”** — 이 모듈 조합으로 당시 mAP를 큰 폭으로 끌어올린 방식.

# 핵심 아이디어 (왜 잘됐나)

- **영역 제안(Region Proposals)**: 전 장면을 샅샅이 스캔하지 않고, **Selective Search** 등으로 “물체일 법한” 후보 박스 ~2k개만 평가 → 연산을 집중.
- **강력한 특징 추출기(CNN 전이학습)**: ImageNet으로 **사전학습(pretrain)**한 **AlexNet 계열**을 후보마다 순전파 → **4096차원**의 강한 표현력 확보.
- **간단한 분류기(Linear SVMs)**: 공통 CNN 특징 위에 **클래스별 선형 SVM**만 얹음 → 학습·추론 단순, 클래스 수↑에도 확장 용이.
- **중복 억제(NMS)**: 높은 점수 박스만 남기고 겹치는 박스 제거 → 깔끔한 최종 검출.
- **박스 회귀(BBox Regression)**: 좌표를 **선형 회귀**로 소폭 보정 → **지역화 오류** 줄여 **mAP +3~4pt**.

# 파이프라인 (테스트 시퀀스)

1. 입력 이미지 → **Selective Search**(fast)로 **~2,000** 후보
2. 후보 박스 **워핑(227×227, p=16 컨텍스트 패딩)**
3. **CNN forward** → **4096D** 특징(fc6/7)
4. **클래스별 선형 SVM**으로 점수
5. **클래스별 NMS**
6. **(선택) 박스 회귀**로 좌표 보정

# 학습 전략 (데이터 적음 문제를 이렇게 풀었다)

- **1단계: 사전학습** — ImageNet **분류**로 CNN을 학습(박스 라벨 불필요).
- **2단계: 미세조정(fine-tuning)** — 워핑된 후보를 입력으로 **(N+1)-way** 분류(배경 포함). **IoU ≥ 0.5**를 양성으로 넉넉히.
- **3단계: SVM 학습** — 양성=**정답 박스**, 음성=**IoU < 0.3**(그리드 탐색), **하드 네거티브 마이닝**으로 결정경계 정교화.
- **이유**: 미세조정은 데이터 확대 효과가 필요(양성 폭넓게), SVM은 **정밀 위치**에 민감(양성 좁게).

# 성능 & 비용(당시 기준)

- **VOC10–12**: mAP **≈53%**(BB 회귀 포함 시 **53.7%**), 기존 BoVW+SPM/ DPM 대비 **대폭↑**
- **ILSVRC13**: mAP **31.4%**, OverFeat(슬라이딩 윈도우) **24.3%** 대비 우세
- **비용 단점**: 후보 **개수만큼 CNN 순전파** → **느림(이미지당 수~십 초)**, 대규모 실시간에는 부적합

# 왜 역사적이었나 (임팩트)

- *핸드크래프트 특징 → 표현학습(CNN)**로 **검출 패러다임 전환**을 촉발.
- 이후 **SPP-net → Fast R-CNN → Faster R-CNN(제안도 CNN화) → Mask R-CNN**으로 진화.
- “**좋은 후보 + 강한 특징 + 얕은 분류기 + 간단한 좌표 보정**”이라는 **모듈 설계 철학**을 확립.

# 장단점 요약

- ✅ 정확도 높음, 표현력 강함, 클래스 확장성 좋음(공유 특징 + 선형 연산)
- ⚠️ **느림**(후보마다 CNN), 제안 생성과 워핑 비용 큼 → **Faster R-CNN**이 이 병목을 해결

# 10초 치트키

- **Proposals(~2k) → Warp(227) → CNN(4096D) → SVMs → NMS → +BBoxReg**
- **Pretrain on ImageNet → Fine-tune on warped regions → SVM with hard negatives**