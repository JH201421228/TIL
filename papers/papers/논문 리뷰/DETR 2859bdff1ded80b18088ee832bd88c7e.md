# DETR

소유자: 주헌 박

- **Direct set prediction for detection.** 객체 검출을 “박스의 집합을 한 번에 예측”하는 문제로 정식화해, 앵커·프로포절·NMS 같은 수작업 구성요소를 제거합니다. 이를 위해 트랜스포머 인코더–디코더와 ‘세트 기반 전역 손실’을 결합합니다.
    
    객체 간 관계와 전역 문맥을 이용해, 고정 개수의 “오브젝트 쿼리”로 병렬 예측합니다.
    
- **Hungarian matching loss.** 예측 N개와 정답을 1:1로 짝지어(헝가리안 알고리즘) 중복을 원천 차단하고, 분류 음의 로그우도 + 박스 손실(L1+GIoU)을 합산해 학습합니다.
- **Architecture in one glance.** 일반 CNN 백본 특징맵 → 1×1 컨브로 차원 축소 → 트랜스포머 인코더(전역 self-attention) → 트랜스포머 디코더(학습된 오브젝트 쿼리 입력) → 공유 FFN이 클래스와 박스를 출력(“no object” 클래스 포함).
- **No anchors, no NMS.** 모델이 처음부터 “중복 없는” 세트를 내놓도록 학습되므로, 후처리 NMS가 본질적으로 불필요합니다(초기 얕은 디코더 층에선 NMS가 약간 도움되지만, 깊어질수록 오히려 해가 됨).
- **Performance vs Faster R-CNN.** COCO에서 파라미터 수가 비슷할 때 AP가 경쟁적(≈42 AP), 큰 객체(APL)에 특히 강하고 작은 객체(APS)는 약합니다.
- **Training recipe differences.** AdamW, 긴 학습 스케줄(300~500 epochs), 디코더 각 층마다 보조 손실(auxiliary loss) 사용이 성능에 유의미합니다.
- **Ablation insights.**
    - 인코더(전역 self-attention) 층을 늘리면 AP가 점진 향상.
    - 디코더 심층화로 층이 진행될수록 중복 억제가 자발적으로 해결되어 NMS 이득이 사라집니다.
    - 박스 손실은 L1 단독보다 GIoU 또는 L1+GIoU 조합이 우수.
- **Object queries specialize.** 쿼리 슬롯들은 이미지 위치/크기 분포에 맞춰 역할이 다소 분화되는 경향을 보입니다.
- **Panoptic segmentation extension.** 디코더 출력에 마스크 헤드를 얹어 stuff/things를 통합적으로 예측하며, COCO-val 기준 PQ에서 강한 성능을 보입니다. 픽셀별 argmax로 간단히 겹침 없는 마스크를 생성합니다.
- **Takeaways for practice.**
    1. “세트 예측+헝가리안 매칭”으로 파이프라인을 단순화한다.
    2. 전역 문맥(self-attention) 덕에 큰 객체에 강하고, 작은 객체는 해상도/피처 계층화(FPN 유사 아이디어)로 보완 여지.
    3. 학습은 길고 ổ정(AdamW, aux losses), 박스 손실은 GIoU와 함께 쓴다.

원문 한 줄 정의를 덧붙이면: **“DETR는 트랜스포머와 1:1 매칭 손실로 객체 검출을 직접 ‘세트 예측’해, 앵커·NMS 없는 간단한 엔드투엔드 파이프라인을 제공한다.”**