# YOLO

소유자: 주헌 박

다음 한 문장에 YOLOv1의 영혼이 다 들어있다: **“이미지 한 장을 단 한 번만 통과시켜(S×S 그리드) 각 셀에서 여러 박스(B개)와 클래스 확률을 바로 회귀해 내는 통합형, 실시간 객체 탐지기.”**

# 핵심 아이디어

- **단일 네트워크, 단일 패스**: 후보영역/별도 분류기/재점수화 같은 다단계를 없애고, **한 번의 forward pass**로 박스와 클래스를 동시에 예측.
- **그리드 책임 할당**: 이미지를 **S×S 격자**로 나누고, **객체 중심이 속한 셀**이 그 객체를 “책임”지고 예측(중복·혼선을 줄임).
- **박스+확률의 직접 회귀**: 셀마다 **B개의 박스 (x, y, w, h, C)** 와 **C개 클래스 조건부 확률** `Pr(class | object)`를 예측.

# 출력과 점수 계산

- **출력 텐서**: `S × S × (B·5 + C)`
    
    (예: VOC에서 S=7, B=2, C=20 → 7×7×30)
    
- **신뢰도(Confidence)**: `C = Pr(object) × IoU(pred, gt)`
- **클래스별 점수(테스트 시)**:
    
    `Score(class c) = Pr(c | object) × C = Pr(c) × IoU`
    

# 손실 설계(학습의 비밀 소스)

- **좌표 가중 강화**: `λ_coord = 5`로 (x, y, √w, √h) 오차를 크게 반영 → 위치 학습에 힘 실어줌.
- **빈 셀 억제**: 물체 없는 셀의 신뢰도 손실에 `λ_noobj = 0.5` → “없는 데 있다고” 학습되는 걸 방지.
- **크기 안정화**: w,h 대신 **√w, √h**를 회귀 → 작은 박스에 민감도↑, 학습 안정화.
- **전이학습**: ImageNet 분류로 **백본 사전학습** 후, 해상도를 448로 높여 탐지에 미세조정.

# 왜 빠른가

- **파이프라인 통합**: 제안→특징→분류→후처리의 **여러 네트워크 호출**이 아니라 **한 네트워크 한 번**.
- **전역 추론**: 전체 이미지를 한 번에 보니 **배경 오검출**이 적음(문맥 활용).
- **실시간 성능**: 기본형 ~45 FPS, 경량형(Fast YOLO) ~150+ FPS(논문 기준).

# 강점 vs 한계

- **강점**
    - 실시간(≥30 FPS)에서도 **준수한 mAP**.
    - **전역 맥락** 덕에 배경에서의 **False Positive↓**.
    - 사진→아트워크 등 **도메인 전이**에서도 성능 하락이 비교적 완만.
- **한계(설계상 제약)**
    - **셀당 박스/클래스 제한** → **가까운 다중 객체**, **작은 객체**에 약함.
    - **다운샘플**로 특징이 다소 거칠어 **정밀 위치(Localization)** 오차가 상대적으로 큼.

# 실전 팁(요약)

- **NMS**로 중복 박스를 정리하면 mAP가 꽤 오른다.
- **강한 데이터 증강**(크롭/색상/왜곡)과 드롭아웃으로 과적합을 완화하라.
- 작은 물체가 많다면 **YOLOv1 그대로**보다, 앵커·멀티스케일·피처피라미드가 들어간 **후속 버전**(v2/v3/…)을 고려하라.

# 계보상 위치(한 줄 메모)

- R-CNN 계열이 **“제안→분류”**의 다단계라면, YOLO는 **“끝판왕 한 방 회귀”**로 패러다임을 바꾼 1세대 **원샷(One-Shot) 탐지**의 출발점. 이후 v2/v3는 **앵커·멀티스케일**로 v1의 작은 물체/정밀 위치 약점을 보완해 나간다.